from __future__ import annotations

import os
import re
from dataclasses import dataclass
from typing import List, Literal, Optional, Sequence

from chromadb import PersistentClient
try:
    from chromadb.errors import InvalidCollectionException, NotFoundError
except ImportError:
    # chromadb ìµœì‹  ë²„ì „ í˜¸í™˜
    try:
        from chromadb.errors import InvalidCollectionException
    except ImportError:
        # InvalidCollectionExceptionë„ ì—†ëŠ” ê²½ìš°
        class InvalidCollectionException(Exception):  # type: ignore[misc]
            # => ChromaDB ë²„ì „ì´ ë‹¬ë¼ì„œ ì›ë˜ ì˜ˆì™¸ê°€ ì—†ë”ë¼ë„
            #    ì½”ë“œê°€ ê¹¨ì§€ì§€ ì•Šê³  ë™ì‘í•˜ë„ë¡ ì„ì‹œ ì˜ˆì™¸ í´ë˜ìŠ¤ë¥¼ ì •ì˜

    class NotFoundError(InvalidCollectionException):  # type: ignore[misc]
        # => get_collection() í˜¸ì¶œ ì‹œ ì»¬ë ‰ì…˜ì´ ì—†ì„ ë•Œ ë°œìƒì‹œí‚¤ê¸° ìœ„í•´
        #    NotFoundError ë¥¼ InvalidCollectionExceptionì˜ ì„œë¸Œí´ë˜ìŠ¤ë¡œ ì •ì˜
        """Fallback for older chromadb API expectation."""


from dotenv import load_dotenv
from openai import OpenAI

# .env íŒŒì¼ì— ìˆëŠ” OPENAI_API_KEY, ê¸°íƒ€ ì„¤ì •ë“¤ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ë¡œë“œ
load_dotenv()

#  RAG ê´€ë ¨ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë“¤

class RAGServiceError(RuntimeError):
    """RAG ì„œë¹„ìŠ¤ì—ì„œ ë°œìƒí•˜ëŠ” ëª¨ë“  ì˜ˆì™¸ì˜ ë² ì´ìŠ¤ í´ë˜ìŠ¤."""
    # => ë‹¤ë¥¸ RAG ê´€ë ¨ ì˜ˆì™¸ë“¤ì´ ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ê²Œ í•´ì„œ
    #    ìƒìœ„ ë ˆë²¨ì—ì„œ í•œ ë²ˆì— ì¡ê¸° ì‰½ë„ë¡ ì„¤ê³„

class EmptyQueryError(RAGServiceError):
    """ì‚¬ìš©ì ì§ˆë¬¸ì´ ë¹„ì–´ ìˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸."""
    # => ìœ íš¨ì„± ê²€ì¦ ë‹¨ê³„ì—ì„œ ì‚¬ìš© (ì§ˆë¬¸ ì—†ëŠ”ë° ëª¨ë¸ í˜¸ì¶œí•˜ëŠ” ê²ƒ ë°©ì§€)


class InappropriateQueryError(RAGServiceError):
    """OpenAI moderationì—ì„œ ë¶€ì ì ˆí•˜ë‹¤ê³  íŒë‹¨í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì˜ˆì™¸."""
    # => ìš•ì„¤, ì„±ì¸/í­ë ¥ ë“± ì •ì±… ìœ„ë°˜ ì§ˆì˜ë¥¼ ë§‰ê³  ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´í•˜ê¸° ìœ„í•´ ì‚¬ìš©


class RetrievalError(RAGServiceError):
    """Chromaì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸."""
    # => ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜, DB ê²½ë¡œ ë¬¸ì œ, ì¿¼ë¦¬ ì˜¤ë¥˜ ë“± RAG 'ê²€ìƒ‰ ë‹¨ê³„' ì‹¤íŒ¨ ìƒí™© í‘œí˜„


#  RAGì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ ì“°ëŠ” ë°ì´í„° êµ¬ì¡°

@dataclass
class RetrievalContext:
    # ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ë½‘ì•„ë‚¸ ì»¨í…ìŠ¤íŠ¸ ë¬¶ìŒ.
    context: str
    pdf_links: List["ReferenceLink"]
    embed_ids: List[str]


@dataclass
class RAGResult:
    # RAG ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ ìµœì¢… ê²°ê³¼.
    answer: str
    pdf_links: List["ReferenceLink"]
    prompt_type: Literal["greet", "answer", "fallback"]
    embed_ids: Optional[List[str]] = None


@dataclass
class ReferenceLink:
    # ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œí•  'ì°¸ê³  ë§í¬' ì •ë³´.
    title: str
    url: str


class RAGService:
    # ê°„ë‹¨í•œ ì¸ì‚¬/í…ŒìŠ¤íŠ¸ íŒ¨í„´ì„ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì •ì˜
    GREET_PATTERN = re.compile(r"^\s*(ì•ˆë…•|ã…ã…‡|í•˜ì´|hi|hello|í…ŒìŠ¤íŠ¸|ê³ ë§ˆì›Œ|ê°ì‚¬)\s*$", re.I)

    #  ëª¨ë¸/ê²½ë¡œ/ì„ê³„ê°’ ë“± ê³µí†µ ì„¤ì •ì„ ë¬¶ì–´ì„œ ì´í›„ í˜¸ì¶œì„ ë‹¨ìˆœí™”
    def __init__(
        self,
        *,
        db_path: str = "./chroma_db_v1",
        collection_name: str = "monthfarmtech_v1",
        n_results: int = 15,
        distance_threshold: float = 1.12,
        min_docs: int = 1,
        pdf_limit: int = 3,
        context_limit: int = 1800,
        openai_model: str = "gpt-4.1-mini",
        embedding_model: str = "text-embedding-3-small",
    ) -> None:
        # .envë¥¼ ë¡œë“œí•˜ê³  í‚¤ ì—†ìœ¼ë©´ ì˜ˆì™¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key: 
            raise RAGServiceError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._client = OpenAI(api_key=api_key)

        # 2) ChromaDB í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
        self._chroma = PersistentClient(path=db_path)

        try:  
            # ì§€ì •í•œ ì´ë¦„ì˜ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
            self._collection = self._chroma.get_collection(collection_name)
        except (NotFoundError, InvalidCollectionException) as exc:
            # ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜ ì†ìƒëœ ê²½ìš° â†’ RetrievalErrorë¡œ ê°ì‹¸ì„œ ì˜¬ë¦¼
            raise RetrievalError(
                f"'{collection_name}' ì»¬ë ‰ì…˜ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Chroma DBë¥¼ ì ê²€í•´ì£¼ì„¸ìš”."
            ) from exc

        # 3) ë‚˜ë¨¸ì§€ ì„¤ì • ê°’ë“¤ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self._n_results = n_results
        self._distance_threshold = distance_threshold
        self._min_docs = min_docs
        self._pdf_limit = pdf_limit
        self._context_limit = context_limit
        self._openai_model = openai_model
        self._embedding_model = embedding_model

    # RAG ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜í–‰í•˜ëŠ” "ì›ìƒ· ë©”ì„œë“œ"
    def ask(self, raw_query: str) -> RAGResult:
        # 1) ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì„ ì •ì œ
        query = (raw_query or "").strip()

        # ë¹ˆ ë¬¸ìì—´ì´ë©´ ì¦‰ì‹œ ì˜ˆì™¸ ë°œìƒ â†’ LLM í˜¸ì¶œ ë‚­ë¹„ ë°©ì§€
        if not query:
            raise EmptyQueryError("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # 2) Moderation ê²€ì‚¬ (ìš•ì„¤/í­ë ¥ì„±/í˜ì˜¤/ì„±ì¸ ë“± ì°¨ë‹¨)
        if self._is_inappropriate(query):
            raise InappropriateQueryError("ë¶€ì ì ˆí•˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì€ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 3) ê¸°ë³¸ ì‘ë‹µ ì´ˆê¸°í™”
        prompt_type: Literal["greet", "answer", "fallback"]
        pdf_links: List[ReferenceLink] = []
        embed_ids: Optional[List[str]] = None

        # 4) ì¸ì‚¬ë§ ì—¬ë¶€ ì²´í¬
        if self.GREET_PATTERN.match(query):
            prompt = self._build_prompt_greet(query)
            prompt_type = "greet"

        else:
            # 5) ê²€ìƒ‰ ë‹¨ê³„ â€” ë²¡í„°DBì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
            retrieval = self._build_retrieval_context(query)

            if retrieval:
                # ê²€ìƒ‰ ì„±ê³µ
                prompt = self._build_prompt_answer(query, retrieval.context, retrieval.embed_ids, retrieval.pdf_links)
                # UIì—ì„œ ì°¸ê³ ìë£Œë¡œ ë³´ì—¬ì¤„ PDF ë§í¬ ì „ë‹¬
                pdf_links = retrieval.pdf_links
                embed_ids = retrieval.embed_ids
                prompt_type = "answer"

            else:
                # ê²€ìƒ‰ ì‹¤íŒ¨ â†’ ë°±ì—… í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ì¼ë°˜ì  ì„¤ëª… ìœ„ì£¼)
                prompt = self._build_prompt_fallback(query)
                prompt_type = "fallback"

        # 6) GPT ëª¨ë¸ í˜¸ì¶œ (ì•ˆì „í•œ ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
        answer = self._call_gpt(prompt)

        # 7) í‘œì¤€í™”ëœ RAG ê²°ê³¼ ê°ì²´ ìƒì„±
        return RAGResult(answer=answer, pdf_links=pdf_links, prompt_type=prompt_type, embed_ids=embed_ids)

    # Moderation(ë¶€ì ì ˆ ì»¨í…ì¸ ) ì°¨ë‹¨
    def _is_inappropriate(self, query: str) -> bool:
        moderation = self._client.moderations.create(model="omni-moderation-latest", input=query)
        return bool(moderation.results[0].flagged)

    # GPT í˜¸ì¶œ â€” í”„ë¡¬í”„íŠ¸ë¥¼ OpenAI ëª¨ë¸ì— ì „ë‹¬í•˜ê³  ê²°ê³¼ë§Œ ì¶”ì¶œ
    def _call_gpt(self, prompt: str) -> str:
        # OpenAI Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ìš”ì²­.
        try:
            response = self._client.responses.create(
                model=self._openai_model,
                input=[{"role": "user", "content": prompt}],
            )            
        except Exception as exc:
            raise RAGServiceError("GPT í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.") from exc
        
        # output_textëŠ” ëª¨ë¸ì´ ìƒì„±í•œ ìµœì¢… í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ëŠ” ë‹¨ì¶• í”„ë¡œí¼í‹°
        return response.output_text

    # ì‘ë¬¼ëª… ìë™ ì¶”ì¶œ â€” ì§ˆì˜ì—ì„œ í•œê¸€ ëª…ì‚¬ ì¤‘ ì‹¤ì œ ë¬¸ì„œì—ì„œ
    # ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë§Œ "ì‘ë¬¼"ë¡œ ê°„ì£¼í•˜ì—¬ í•„í„°ë§
    def _extract_crop_name(self, query: str, metas, kept_idx):
        """
        ì§ˆë¬¸ì—ì„œ í•œê¸€ ëª…ì‚¬ í›„ë³´ë¥¼ ë½‘ê³ ,
        RAG ë©”íƒ€ë°ì´í„°(title/curationNm)ì— ì‹¤ì œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë©´ ì‘ë¬¼ëª…ìœ¼ë¡œ ê°„ì£¼.
        """
        # 1) ì§ˆë¬¸ì—ì„œ í•œê¸€ë§Œ ì¶”ì¶œ (ì˜ì–´/ìˆ«ì ì œê±°)
        tokens = re.findall(r"[ê°€-í£]+", query)

        # 2ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ ë‚¨ê¹€ (ë„ˆë¬´ ì§§ì€ ëª…ì‚¬ëŠ” ì¡ìŒì´ ë§ìŒ)
        cands = [t for t in tokens if len(t) >= 2]

        if not cands:
            return None

        # 2) ê²€ìƒ‰ì—ì„œ ì‚´ì•„ë‚¨ì€ ë©”íƒ€ë°ì´í„°ë“¤ì—ì„œ ì œëª©(title)ë§Œ ìˆ˜ì§‘
        titles = []
        for i in kept_idx:
            m = metas[i]
            title = (m.get("title") or m.get("curationNm") or "").strip()
            if title:
                titles.append(title)

        if not titles:
            return None

        # 3) ëª¨ë“  ì œëª©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
        #    â†’ "í† ë§ˆí†  ìë§ˆë¦„ ë³‘ ì˜ˆë°© ê°ì ê³µë™ë³‘" ê°™ì€ í˜•íƒœ
        joined = " ".join(titles)

        # 4) ì‘ë¬¼ëª… í›„ë³´(cands)ê°€ ì œëª© ì•ˆì— ì‹¤ì œë¡œ ë“±ì¥í•˜ë©´ ë°˜í™˜
        for cand in cands:
            if cand in joined:
                return cand

        # ì—†ë‹¤ë©´ ì‘ë¬¼ëª… íŒë‹¨ ë¶ˆê°€
        return None


    # RAG íŒŒì´í”„ë¼ì¸ì—ì„œ "ê²€ìƒ‰"ì„ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜.
    #  ì‹¤íŒ¨ ì‹œì—ëŠ” None ë°˜í™˜ â†’ fallback í”„ë¡¬í”„íŠ¸ë¡œ ì´ì–´ì§.
    def _build_retrieval_context(self, query: str) -> Optional[RetrievalContext]:
        
        # 1) Query â†’ Embedding
        try:
            embedding = self._client.embeddings.create(model=self._embedding_model, input=[query]).data[0].embedding
        except Exception as exc:  # OpenAI errors
            # OpenAI Embedding ëª¨ë¸ ì‹¤íŒ¨ (ë„¤íŠ¸ì›Œí¬, í‚¤ë¬¸ì œ, ëª¨ë¸ ì¥ì•  ë“±)
            raise RAGServiceError("ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from exc

        # 2) ChromaDB ê²€ìƒ‰
        try:
            query_result = self._collection.query(
                query_embeddings=[embedding],
                n_results=self._n_results,
                include=["documents", "metadatas", "distances"],
            )
        except Exception as exc:  # Chroma errors
            raise RetrievalError("ì§€ì‹ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.") from exc

        # 3) ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
        #    ChromaëŠ” nested êµ¬ì¡°ë¡œ ë°˜í™˜í•˜ë¯€ë¡œ 0ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
        docs = query_result.get("documents", [[]])[0]
        metas = query_result.get("metadatas", [[]])[0]
        dists = query_result.get("distances", [[]])[0]
        ids_hit = query_result.get("ids", [[]])[0]

        # 4) ê±°ë¦¬ í•„í„°ë§ â€” relevance filtering
        kept = [
            (doc, meta or {}, id_hit, dist)
            for doc, meta, id_hit, dist in zip(docs, metas, ids_hit, dists)
            if dist <= self._distance_threshold
        ]

        # ë¬¸ì„œê°€ ê±°ì˜ ì—†ìœ¼ë©´ ê²€ìƒ‰ ì‹¤íŒ¨ë¡œ ê°„ì£¼ â†’ fallback
        if len(kept) < self._min_docs:
            return None

        # 5) **ì¶”ê°€ í•„í„°ë§ â€” ì‘ë¬¼ëª… ê¸°ë°˜ ê²€ìƒ‰ ê°•í™”**
        kept_idx = list(range(len(kept)))

        # ì§ˆë¬¸ì— "í† ë§ˆí† ", "ê°ì" ë“± ì‘ë¬¼ëª…ì´ ìˆì„ ê²½ìš°
        # RAG ê²°ê³¼ ì¤‘ í•´ë‹¹ ì‘ë¬¼ëª…ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë§Œ ë‚¨ê¸°ë„ë¡ í•„í„°ë§.
        crop = self._extract_crop_name(query, metas, kept_idx)

        if crop:
            filtered = []
            for idx in kept_idx:
                doc, meta, id_hit, dist = kept[idx]
                title = (meta.get("title") or meta.get("curationNm") or "")
                
                # ì œëª© í˜¹ì€ ë¬¸ì„œ ìì²´ì— ì‘ë¬¼ëª…ì´ ë“±ì¥í•˜ëŠ” ê²½ìš°ë§Œ ìœ ì§€
                if crop in title or crop in doc:
                    filtered.append(idx)

            if filtered:
                kept = [kept[i] for i in filtered]

        # 6) context ìƒì„± â€” ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ë¬¸ì„œë“¤ë§Œ í•©ì³ì„œ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
        context = "\n\n".join(doc for doc, _, _, _ in kept)[: self._context_limit]
        
        # 7) PDF ë§í¬ ì¶”ì¶œ
        pdf_links = self._extract_pdf_links(kept)
        
        # 8) ì‚¬ìš©ëœ ë¬¸ì„œë“¤ì˜ ì„ë² ë”© ID ì¶”ì¶œ
        embed_ids = [id_hit for _, _, id_hit, _ in kept][: self._min_docs]
        
        # 9) RetrievalContext ê°ì²´ ìƒì„± â†’ ask()ì—ì„œ prompt ë¹Œë“œë¥¼ ìœ„í•´ ì‚¬ìš©
        return RetrievalContext(context=context, pdf_links=pdf_links, embed_ids=embed_ids)

    # PDF ë§í¬ ì¶”ì¶œ â€” ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì—ì„œ PDF URLë§Œ ì •ì œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸í™”
    def _extract_pdf_links(self, records: Sequence[tuple[str, dict, str, float]]) -> List[ReferenceLink]:
        pdfs: List[ReferenceLink] = []
        seen_urls: set[str] = set()


        for _, meta, _, _ in records:
            # URL í›„ë³´ í‚¤ ì¤‘ í•˜ë‚˜ë¼ë„ ì¡´ì¬í•˜ë©´ ì‚¬ìš©
            raw_url = (meta.get("pdf_path") or meta.get("atchmnflUrl") or meta.get("linkUrl") or "").strip()
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ URL ë˜ëŠ” ì¤‘ë³µ URLì€ ìŠ¤í‚µ
            if not raw_url or raw_url in seen_urls:
                continue
            
            # ì œëª©ë„ ì—¬ëŸ¬ í‚¤ ì¤‘ ê°€ëŠ¥í•œ ê²ƒì„ ì„ íƒ
            title = (meta.get("title") or meta.get("curationNm") or meta.get("document_title") or "").strip()
            
            # ì œëª©ë„ ì—†ìœ¼ë©´ URL ìì²´ë¥¼ titleë¡œ ì‚¬ìš©
            if not title:
                title = raw_url

            pdfs.append(ReferenceLink(title=title, url=raw_url))
            seen_urls.add(raw_url)

            # ë„ˆë¬´ ë§ì€ PDFë¥¼ ì£¼ë©´ UXê°€ ë‚˜ë¹ ì§€ê³  í”„ë¡¬í”„íŠ¸ê°€ ê¸¸ì–´ì§ â†’ ì œí•œ
            if len(pdfs) >= self._pdf_limit:
                break

        return pdfs


    # ê°„ë‹¨í•œ ì¸ì‚¬ë§ ì²˜ë¦¬ìš© í”„ë¡¬í”„íŠ¸.
    @staticmethod
    def _build_prompt_greet(_: str) -> str:
        return (
            "ì•„ì£¼ ì§§ê²Œ ì¸ì‚¬í•˜ê³ , ì´ ë´‡ì€ ë†ì—…(ì‘ë¬¼Â·ì¬ë°°Â·ë³‘í•´ì¶©) íŠ¹í™” ì±—ë´‡ì„ì„ ì•ˆë‚´í•œ ë’¤ "
            "ë†ì—… ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•´ ë‹¬ë¼ê³  ì •ì¤‘íˆ ìš”ì²­í•´ì¤˜. í•œë‘ ë¬¸ì¥ë§Œ."
        )

    # ê²€ìƒ‰ ì„±ê³µ ì‹œ ì‚¬ìš©ë˜ëŠ” 'ì •ì‹ RAG ë‹µë³€ í”„ë¡¬í”„íŠ¸'.
    @staticmethod
    def _build_prompt_answer(query: str, context: str, embed_ids: Sequence[str], pdf_links: Sequence[ReferenceLink]) -> str:
        
        # PDF ë§í¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        links = "\n".join(f"{link.title}: {link.url}" for link in pdf_links) if pdf_links else ""
        
        # IDë“¤ì„ ì‰¼í‘œë¡œ ì—°ê²°
        ids_str = ", ".join(embed_ids) if embed_ids else ""
        return (
            f"ì§ˆë¬¸: {query}\n\n"
            f"ê²€ìƒ‰ëœ ë‚´ìš©:\n{context}\n\n"
            f"ì°¸ê³  PDF ë§í¬:\n{links}\n\n"
            f"ê´€ë ¨ ì„ë² ë”© ID: {ids_str}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 10ì¤„ ì •ë„ë¡œ ë‹µë³€í•´ì£¼ê³  ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•˜ë¼ê³  í•´ì¤˜."
        )

    @staticmethod
    def _build_prompt_fallback(query: str) -> str:
        return (
            f"ì‚¬ìš©ì ì§ˆë¬¸: {query}\n\n"
            "ì£¼ì œê°€ ë†ì—… ê´€ë ¨ì´ì§€ë§Œ í˜„ì¬ ì œê³µ ë°ì´í„°ì—ëŠ” ì¶©ë¶„í•œ ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤. "
            "ê°„ë‹¨í•œ ì¼ë°˜ ì •ë³´ ìˆ˜ì¤€ìœ¼ë¡œ 2~3ë¬¸ì¥ ìš”ì•½ ì œê³µ í›„, "
            "ë§ˆì§€ë§‰ì— 'ì´ ì£¼ì œëŠ” í˜„ì¬ ì €í¬ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„ ì¼ë°˜ì ì¸ ì •ë³´ë§Œ ì•ˆë‚´ë“œë ¸ì–´ìš”."
            "ì‘ë¬¼ëª…Â·ì¦ìƒÂ·ì§€ì—­ì„ í•¨ê»˜ ì•Œë ¤ì£¼ì‹œë©´ ë” ì‹ ë¢°ë„ ë†’ì€ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ™‚'ë¼ê³  ì•ˆë‚´í•´ì¤˜."
        )
