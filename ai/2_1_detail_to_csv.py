import time
import requests
from urllib.parse import quote_plus
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import pandas as pd
import re

# 1ï¸âƒ£ í™˜ê²½ì„¤ì •
load_dotenv()
API_KEY = quote_plus(os.getenv("NONGSARO_API_KEY"))
URL = "http://api.nongsaro.go.kr/service/monthFarmTech/monthFarmTechDtl"
HEADERS = {"Referer": "https://xn--cp5bxm.site"}  # ìŠ¹ì¸ëœ ë„ë©”ì¸

# 2ï¸âƒ£ CSV ì½ê¸° (ì•ì—ì„œ ë§Œë“  íŒŒì¼)
df = pd.read_csv("1monthTech_list_sample.csv")

# 3ï¸âƒ£ 
rows = df.to_dict(orient="records")
details = []

# â€œë³¸ë¬¸ë§Œâ€ ë½‘ê²Œ ë°”ê¿€ ìˆ˜ ìˆëŠ” í•¨ìˆ˜
def extract_main_text(html: str) -> str:
    if not html:
        return ""
    doc = BeautifulSoup(html, "lxml")

    # ë…¸ì´ì¦ˆ ì œê±°
    for t in doc(["script","style","header","footer","nav","aside","form","button",
                  "figure","img","svg","iframe","caption","colgroup","col"]):
        t.decompose()

    # í‘œ ì „ë¶€ ì œê±°
    for t in doc.find_all(["table","thead","tbody","tr","th","td"]):
        t.decompose()

    # ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    for br in doc.find_all(["br","hr"]):
        br.replace_with("\n")

    # í—ˆìš© íƒœê·¸ ì™¸ ì–¸ë©
    allow = {"h1","h2","h3","p","li","ul","ol"}
    for tag in doc.find_all(True):
        if tag.name not in allow:
            tag.unwrap()

    text = doc.get_text("\n")
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

for idx, r in enumerate(rows, 1):
    curation_no = str(r.get("curationNo", "")).strip()
    cntnts_snn = 1  # ë³´í†µ 1ë²ˆë¶€í„° ì‹œì‘ (í•„ìš”ì‹œ ë°˜ë³µë¬¸ìœ¼ë¡œ 2~5ê¹Œì§€ ì‹œë„ ê°€ëŠ¥)

    print(f"ğŸ“˜ {idx}. {curation_no} ìƒì„¸ ìš”ì²­ ì¤‘...")

    params = {
        "apiKey": API_KEY,
        "srchCurationNo": curation_no,
        "srchCntntsSnn": cntnts_snn
    }

    res = requests.get(URL, params=params, headers=HEADERS, timeout=15)
    res.encoding = "utf-8"
    xml = res.text

    soup = BeautifulSoup(xml, "lxml-xml")
    item = soup.find("item")
    if not item:
        print(f"âŒ {curation_no} ë°ì´í„° ì—†ìŒ")
        continue

    html = (item.find("cntntsInfoHtml").text if item.find("cntntsInfoHtml") else "").strip()
    text = extract_main_text(html)


    details.append({
        "curationNo": curation_no,
        "title": r.get("cntntsSj", ""),
        "html": html,
        "text": text
    })
    time.sleep(0.5)  # API ê³¼ë¶€í•˜ ë°©ì§€

# 4ï¸âƒ£ ì €ì¥
out_path = "21monthTech_detail_sample.csv"
# âœ… ìˆ˜ì • ë²„ì „ â€” html ì œê±°í•˜ê³  textë§Œ ì €ì¥
pd.DataFrame(details)[["curationNo", "title", "text"]].to_csv(
    out_path, index=False, encoding="utf-8-sig"
)

print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {out_path} ({len(details)}ê±´)")
